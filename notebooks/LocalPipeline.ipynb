{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFRS9 Local Pipeline Execution\n",
    "\n",
    "This notebook demonstrates the complete IFRS9 pipeline execution locally using PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('/home/jovyan/src')\n",
    "\n",
    "from generate_data import DataGenerator\n",
    "from rules_engine import IFRS9RulesEngine\n",
    "from validation import DataValidator\n",
    "from ml_model import CreditRiskClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark with proper configuration\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IFRS9LocalPipeline\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Spark UI: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic loan portfolio\n",
    "print(\"Generating synthetic data...\")\n",
    "generator = DataGenerator(seed=42)\n",
    "\n",
    "# Generate datasets\n",
    "loans_df = generator.generate_loan_portfolio(n_loans=5000)\n",
    "payments_df = generator.generate_payment_history(loans_df, n_months=6)\n",
    "macro_df = generator.generate_macroeconomic_data()\n",
    "\n",
    "print(f\"Generated:\")\n",
    "print(f\"  - Loans: {len(loans_df):,} records\")\n",
    "print(f\"  - Payments: {len(payments_df):,} records\")  \n",
    "print(f\"  - Macro data: {len(macro_df):,} records\")\n",
    "\n",
    "# Save to temporary files\n",
    "loans_df.to_csv('/tmp/loan_portfolio.csv', index=False)\n",
    "payments_df.to_csv('/tmp/payment_history.csv', index=False)\n",
    "macro_df.to_csv('/tmp/macro_data.csv', index=False)\n",
    "\n",
    "print(\"Data saved to /tmp/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data quality\n",
    "print(\"Running data validation...\")\n",
    "validator = DataValidator()\n",
    "\n",
    "# Validate loan portfolio\n",
    "loans_passed, loans_errors = validator.validate_loan_portfolio(loans_df)\n",
    "print(f\"Loan validation: {'PASSED' if loans_passed else 'FAILED'}\")\n",
    "if loans_errors:\n",
    "    for error in loans_errors:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "# Validate payments\n",
    "payments_passed, payments_errors = validator.validate_payment_history(payments_df)\n",
    "print(f\"Payment validation: {'PASSED' if payments_passed else 'FAILED'}\")\n",
    "if payments_errors:\n",
    "    for error in payments_errors:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "# Data quality report\n",
    "quality_report = validator.check_data_quality(loans_df)\n",
    "print(f\"\\nData Quality Metrics:\")\n",
    "print(f\"  - Completeness Score: {quality_report['completeness_score']:.1f}%\")\n",
    "print(f\"  - Total Records: {quality_report['total_records']:,}\")\n",
    "print(f\"  - Total Columns: {quality_report['total_columns']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. IFRS9 Rules Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process loans through IFRS9 rules engine\n",
    "print(\"Processing IFRS9 rules...\")\n",
    "engine = IFRS9RulesEngine(spark=spark)\n",
    "\n",
    "# Load data into Spark DataFrame\n",
    "spark_loans_df = spark.createDataFrame(loans_df)\n",
    "\n",
    "print(f\"Loaded {spark_loans_df.count():,} loans into Spark\")\n",
    "print(\"Spark DataFrame Schema:\")\n",
    "spark_loans_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply IFRS9 processing\n",
    "processed_df = engine.process_portfolio(spark_loans_df)\n",
    "\n",
    "print(f\"Processing complete!\")\n",
    "print(f\"Processed {processed_df.count():,} loans\")\n",
    "\n",
    "# Show sample results\n",
    "print(\"\\nSample processed records:\")\n",
    "processed_df.select(\n",
    "    \"loan_id\", \"loan_type\", \"credit_score\", \"days_past_due\", \n",
    "    \"calculated_stage\", \"calculated_pd\", \"calculated_lgd\", \"calculated_ecl\", \"risk_rating\"\n",
    ").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validation and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation on IFRS9 calculations\n",
    "print(\"Validating IFRS9 calculations...\")\n",
    "validations = engine.validate_calculations(processed_df)\n",
    "\n",
    "print(\"\\nValidation Results:\")\n",
    "for validation in validations:\n",
    "    status = \"✓\" if validation[\"passed\"] else \"✗\"\n",
    "    print(f\"  {status} {validation['check']}: {validation['message']}\")\n",
    "\n",
    "# Generate summary report\n",
    "print(\"\\nGenerating summary report...\")\n",
    "summary = engine.generate_summary_report(processed_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IFRS9 PORTFOLIO SUMMARY REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Portfolio metrics\n",
    "metrics = summary[\"portfolio_metrics\"]\n",
    "print(f\"\\nPortfolio Overview:\")\n",
    "print(f\"  Total Loans: {metrics['total_loans']:,}\")\n",
    "print(f\"  Total Exposure: ${metrics['total_exposure']:,.2f}\")\n",
    "print(f\"  Total ECL: ${metrics['total_ecl']:,.2f}\")\n",
    "print(f\"  Coverage Ratio: {metrics['coverage_ratio']:.2%}\")\n",
    "\n",
    "# Stage distribution\n",
    "print(f\"\\nStage Distribution:\")\n",
    "for stage, data in summary[\"stage_distribution\"].items():\n",
    "    print(f\"  {stage}: {data['count']:,} loans (${data['exposure']:,.2f} exposure, ${data['ecl']:,.2f} ECL)\")\n",
    "\n",
    "# Risk distribution\n",
    "print(f\"\\nRisk Rating Distribution:\")\n",
    "for rating, data in summary[\"risk_distribution\"].items():\n",
    "    print(f\"  {rating}: {data['count']:,} loans (avg PD: {data['avg_pd']:.2%}, ECL: ${data['ecl']:,.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Machine Learning Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ML models for credit risk prediction\n",
    "print(\"Training ML models...\")\n",
    "classifier = CreditRiskClassifier(model_type=\"random_forest\")\n",
    "\n",
    "# Convert Spark DataFrame to Pandas for ML training\n",
    "ml_df = processed_df.toPandas()\n",
    "\n",
    "# Prepare features\n",
    "X, feature_names = classifier.prepare_features(ml_df)\n",
    "print(f\"Prepared {len(feature_names)} features for ML training\")\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "\n",
    "# Show feature names\n",
    "print(f\"\\nTop 10 features: {feature_names[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train stage classifier\n",
    "print(\"Training stage classifier...\")\n",
    "stage_metrics = classifier.train_stage_classifier(X, ml_df[\"calculated_stage\"], test_size=0.3)\n",
    "\n",
    "print(f\"\\nStage Classifier Results:\")\n",
    "print(f\"  Accuracy: {stage_metrics['accuracy']:.2%}\")\n",
    "print(f\"  CV Mean: {stage_metrics['cv_mean']:.2%} (±{stage_metrics['cv_std']:.2%})\")\n",
    "if stage_metrics.get('roc_auc'):\n",
    "    print(f\"  ROC AUC: {stage_metrics['roc_auc']:.3f}\")\n",
    "\n",
    "print(f\"\\nTop 5 Important Features for Stage Classification:\")\n",
    "for feature in stage_metrics['feature_importance'][:5]:\n",
    "    print(f\"  - {feature['feature']}: {feature['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PD model\n",
    "print(\"Training PD regression model...\")\n",
    "pd_metrics = classifier.train_pd_model(X, ml_df[\"calculated_pd\"], test_size=0.3)\n",
    "\n",
    "print(f\"\\nPD Model Results:\")\n",
    "print(f\"  MAE: {pd_metrics['mae']:.4f}\")\n",
    "print(f\"  RMSE: {pd_metrics['rmse']:.4f}\")\n",
    "print(f\"  R² Score: {pd_metrics['r2_score']:.3f}\")\n",
    "print(f\"  CV MAE: {pd_metrics['cv_mae_mean']:.4f} (±{pd_metrics['cv_mae_std']:.4f})\")\n",
    "\n",
    "print(f\"\\nTop 5 Important Features for PD Prediction:\")\n",
    "for feature in pd_metrics['feature_importance'][:5]:\n",
    "    print(f\"  - {feature['feature']}: {feature['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Predictions and Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on new data\n",
    "print(\"Making predictions on test data...\")\n",
    "\n",
    "# Take a sample for demonstration\n",
    "test_sample = X.iloc[:10]\n",
    "\n",
    "# Predict stages\n",
    "predicted_stages, stage_probabilities = classifier.predict_stage(test_sample)\n",
    "predicted_pd = classifier.predict_pd(test_sample)\n",
    "\n",
    "print(\"\\nPrediction Results (First 10 loans):\")\n",
    "print(\"-\" * 80)\n",
    "for i in range(len(predicted_stages)):\n",
    "    loan_id = ml_df.iloc[i]['loan_id']\n",
    "    actual_stage = ml_df.iloc[i]['calculated_stage']\n",
    "    pred_stage = predicted_stages[i]\n",
    "    pred_pd = predicted_pd[i]\n",
    "    \n",
    "    print(f\"Loan {loan_id}: Actual={actual_stage}, Predicted={pred_stage}, PD={pred_pd:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain a specific prediction\n",
    "print(\"Explaining prediction for first loan...\")\n",
    "explanation = classifier.explain_prediction(test_sample, index=0)\n",
    "\n",
    "print(f\"\\nPrediction Explanation for Loan {ml_df.iloc[0]['loan_id']}:\")\n",
    "print(f\"  Predicted Stage: {explanation['predicted_stage']}\")\n",
    "if 'predicted_pd' in explanation:\n",
    "    print(f\"  Predicted PD: {explanation['predicted_pd']:.3f}\")\n",
    "\n",
    "print(f\"\\n  Stage Probabilities:\")\n",
    "for stage, prob in explanation['stage_probabilities'].items():\n",
    "    print(f\"    {stage}: {prob:.3f}\")\n",
    "\n",
    "print(f\"\\n  Top Contributing Features:\")\n",
    "for feature in explanation['top_features']:\n",
    "    print(f\"    {feature['feature']}: {feature['value']:.2f} (importance: {feature['importance']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed results\n",
    "print(\"Saving results...\")\n",
    "\n",
    "# Save processed data\n",
    "processed_pandas = processed_df.toPandas()\n",
    "processed_pandas.to_csv('/tmp/ifrs9_processed.csv', index=False)\n",
    "\n",
    "# Save summary report\n",
    "with open('/tmp/ifrs9_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "# Save model performance metrics\n",
    "model_metrics = {\n",
    "    'stage_classifier': stage_metrics,\n",
    "    'pd_model': pd_metrics,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open('/tmp/model_metrics.json', 'w') as f:\n",
    "    json.dump(model_metrics, f, indent=2, default=str)\n",
    "\n",
    "print(\"Results saved to /tmp/:\")\n",
    "print(\"  - ifrs9_processed.csv: Processed loan data\")\n",
    "print(\"  - ifrs9_summary.json: Portfolio summary report\") \n",
    "print(\"  - model_metrics.json: ML model performance metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "print(\"Cleaning up resources...\")\n",
    "engine.stop()\n",
    "print(\"Pipeline execution completed successfully!\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE EXECUTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Data Generation: {len(loans_df):,} loans\")\n",
    "print(f\"✓ Data Validation: {'Passed' if loans_passed and payments_passed else 'Issues found'}\")\n",
    "print(f\"✓ IFRS9 Processing: {processed_df.count():,} loans processed\")\n",
    "print(f\"✓ ML Training: Stage accuracy {stage_metrics['accuracy']:.1%}, PD MAE {pd_metrics['mae']:.4f}\")\n",
    "print(f\"✓ Results Saved: 3 output files in /tmp/\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python", 
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}