# IFRS9 Risk Management System

[![CI/CD Pipeline](https://github.com/your-org/ifrs9-risk-system/workflows/CI/badge.svg)](https://github.com/your-org/ifrs9-risk-system/actions)
[![Security Scan](https://github.com/your-org/ifrs9-risk-system/workflows/Security/badge.svg)](https://github.com/your-org/ifrs9-risk-system/security)
[![Code Coverage](https://codecov.io/gh/your-org/ifrs9-risk-system/branch/main/graph/badge.svg)](https://codecov.io/gh/your-org/ifrs9-risk-system)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ¦ Overview

A comprehensive, enterprise-grade IFRS9 credit risk management system designed for financial institutions to ensure regulatory compliance while providing advanced analytics and real-time monitoring capabilities.

### ğŸ¯ Key Features

- **IFRS9 Compliance**: Automated staging classification and ECL calculations
- **Advanced ML Models**: XGBoost, LightGBM, and CatBoost for risk prediction
- **Explainability**: Rule-based narratives with SHAP-driven model transparency
- **Real-time Dashboards**: Looker Studio integration with 7 comprehensive dashboards
- **Cloud-Native**: Google Cloud Platform with auto-scaling capabilities
- **Production-Ready**: Kubernetes deployment with monitoring and alerting

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚â”€â”€â”€â”€â–¶â”‚  Validation  â”‚â”€â”€â”€â”€â–¶â”‚  IFRS9 Engine   â”‚
â”‚  (CSV/Parquet)  â”‚     â”‚   (Pandera)  â”‚     â”‚   (PySpark)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ML Models     â”‚â—€â”€â”€â”€â”€â”‚   Airflow    â”‚â”€â”€â”€â”€â–¶â”‚    Reports      â”‚
â”‚  (Scikit-learn) â”‚     â”‚ (Orchestrator)â”‚     â”‚  (Dashboard)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- 8GB+ RAM
- 10GB+ free disk space

## â˜ï¸ GCP Deployment (Portfolio)

Two Terraform options exist:
- **Portfolio/minimal (recommended for demos)**: `deploy/portfolio/terraform/README.md`
- **Production/complete**: `deploy/terraform/README.md`

### âš ï¸ Important Notes
- **Project-specific naming**: All Docker files use IFRS9-specific names to avoid conflicts
- **Dynamic ports**: Uses environment variables for port configuration 
- **Dependency compatibility**: Optimized versions to resolve PySpark/Airflow conflicts
- **Staged installation**: Dependencies installed in stages to prevent conflicts

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/ifrs9-risk-system.git
cd ifrs9-risk-system
```

2. **Set up environment**
```bash
make setup
```
This will:
- Copy `.env.example` to `.env`
- Create necessary directories
- Build Docker images

3. **Initialize Airflow**
```bash
make init-airflow
```

4. **Start all services**
```bash
make up
```
This uses the renamed `docker-compose.ifrs9.yml` file.

5. **Check service ports**
```bash
make show-ports
```

You'll see output like:
```
Service Ports:
================================
jupyter          0.0.0.0:32768->8888/tcp
airflow-webserver 0.0.0.0:32769->8080/tcp
spark-master     0.0.0.0:32770->8080/tcp
================================
Access URLs:
Jupyter Lab: http://localhost:32768 (password: ifrs9)
Airflow UI:  http://localhost:32769 (user: airflow, password: airflow)
Spark UI:    http://localhost:32770
```

## ğŸ“ Project Structure

```
ifrs9-risk-system/
â”œâ”€â”€ data/                   # Data directory
â”‚   â”œâ”€â”€ raw/               # Input data
â”‚   â””â”€â”€ processed/         # Pipeline outputs
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”‚   â”œâ”€â”€ EDA.ipynb         # Exploratory Data Analysis
â”‚   â””â”€â”€ LocalPipeline.ipynb # Local pipeline testing
â”œâ”€â”€ dags/                  # Airflow DAGs
â”‚   â””â”€â”€ ifrs9_pipeline.py # Main pipeline DAG
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ generate_data.py  # Synthetic data generator
â”‚   â”œâ”€â”€ rules_engine.py   # IFRS9 PySpark engine
â”‚   â”œâ”€â”€ validation.py     # Data validation
â”‚   â””â”€â”€ ml_model.py       # ML classifiers
â”œâ”€â”€ tests/                 # Unit tests
â”‚   â””â”€â”€ test_rules.py     # Rules engine tests
â”œâ”€â”€ docker/                # Docker configurations
â”‚   â”œâ”€â”€ airflow/          # Airflow Dockerfile
â”‚   â””â”€â”€ jupyter/          # Jupyter Dockerfile
â”œâ”€â”€ docker-compose.yml     # Service orchestration
â”œâ”€â”€ Makefile              # Utility commands
â””â”€â”€ README.md             # This file
```

## ğŸ”§ Usage

### Generate Synthetic Data
```bash
make generate-data
```

### Run Tests
```bash
make test
```

### Run Linting
```bash
make lint
```

### Format Code
```bash
make format
```

### Access Services

#### Jupyter Lab
Navigate to `http://localhost:<JUPYTER_PORT>` and use token `ifrs9`.

Example notebooks:
- **EDA.ipynb**: Explore the synthetic loan portfolio
- **LocalPipeline.ipynb**: Run the IFRS9 pipeline locally

#### Airflow UI
Navigate to `http://localhost:<AIRFLOW_PORT>` and login with:
- Username: `airflow`
- Password: `airflow`

Enable and trigger the `ifrs9_credit_risk_pipeline` DAG.

#### Spark UI
Monitor Spark jobs at `http://localhost:<SPARK_MASTER_UI_PORT>`.

## ğŸ“Š IFRS9 Implementation

### Stage Classification
- **Stage 1**: Performing loans (DPD < 30 days)
- **Stage 2**: Underperforming loans (30 â‰¤ DPD < 90 days or significant credit risk increase)
- **Stage 3**: Non-performing loans (DPD â‰¥ 90 days)

### ECL Calculation
```
ECL = PD Ã— LGD Ã— EAD

Where:
- PD: Probability of Default
- LGD: Loss Given Default
- EAD: Exposure at Default
```

### Risk Parameters
- **12-month ECL** for Stage 1 loans
- **Lifetime ECL** for Stage 2 and 3 loans
- Dynamic PD based on credit score and days past due
- LGD adjusted for collateral coverage

## ğŸ¤– Machine Learning Models

### Stage Classifier
- **Algorithm**: Random Forest Classifier
- **Features**: Credit score, DPD, LTV ratio, debt-to-income, etc.
- **Performance**: ~85% accuracy on synthetic data

### PD Predictor
- **Algorithm**: Gradient Boosting Regressor
- **Output**: Probability of default (0-1)
- **Validation**: MAE < 0.05 on test set

## â˜ï¸ GCP Integration

### Configuration
Set GCP environment variables in `.env`:
```bash
GCP_PROJECT_ID=your-project-id
GCP_BUCKET_NAME=your-bucket
GCP_DATASET_ID=your-dataset
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
```

### Deployment
```bash
make deploy-gcp  # Coming soon
```

## ğŸ§ª Testing

Run all tests:
```bash
make test
```

Run specific test:
```bash
docker-compose exec jupyter python -m pytest tests/test_rules.py -v
```

## ğŸ“ Development

### Dependency Management
The project uses carefully selected dependency versions to avoid conflicts:
- **PyArrow**: `>=6.0.0,<7.0.0` (compatible with older Airflow providers)
- **PySpark**: `>=3.4.0,<3.5.0` (matches PyArrow compatibility)  
- **Google Cloud**: Versions under 3.0 to prevent BigQuery conflicts
- **Airflow Providers**: Compatible with Airflow 2.6-2.8 range

### Docker Architecture
- **Dockerfile.ifrs9-spark**: Main Spark/Python environment
- **Dockerfile.ifrs9-airflow**: Airflow with PySpark integration
- **Dockerfile.ifrs9-jupyter**: Jupyter Lab with ML libraries
- **docker-compose.ifrs9.yml**: Orchestrates all services with dynamic ports

### Adding New Features
1. Create feature branch
2. Implement changes in `src/`
3. Add tests in `tests/`
4. Update notebooks if needed
5. Run `make lint` and `make format`
6. Submit pull request

### Code Style
- Python: Black formatter, Flake8 linter
- Line length: 100 characters
- Type hints encouraged
- Comprehensive docstrings required

## ğŸ› ï¸ Makefile Commands

| Command | Description |
|---------|-------------|
| `make help` | Show all available commands |
| `make setup` | Initial project setup |
| `make up` | Start all services |
| `make down` | Stop all services |
| `make restart` | Restart all services |
| `make logs` | Show logs for all services |
| `make test` | Run all tests |
| `make lint` | Run linting checks |
| `make format` | Format code with black |
| `make clean` | Clean temporary files |
| `make show-ports` | Display service ports |

## ğŸ“Š Monitoring

### Logs
```bash
make logs  # All services
make logs-service SERVICE=jupyter  # Specific service
```

### Health Checks
All services include health checks. Check status:
```bash
make ps
```

## ğŸ”’ Security

- All sensitive data stored in `.env` (not committed)
- Airflow Fernet key for encryption
- Network isolation between services
- No hardcoded credentials

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“š Documentation

### Resources
- [IFRS9 Standard](https://www.ifrs.org/issued-standards/list-of-standards/ifrs-9-financial-instruments/)
- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- [Airflow Documentation](https://airflow.apache.org/docs/)
- [Docker Documentation](https://docs.docker.com/)

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¥ Author

**ECamposSoria**  
Contact: ecampossoria88@gmail.com

## ğŸ¯ Roadmap

- [ ] Real-time processing with Kafka
- [ ] Advanced ML models (XGBoost, LightGBM)
- [ ] Stress testing scenarios
- [ ] Regulatory reporting templates
- [ ] Cloud deployment automation
- [ ] Performance optimization for 1M+ loans
- [ ] Integration with core banking systems

## âš ï¸ Disclaimer

This is a demonstration project using synthetic data. For production use, ensure compliance with local regulatory requirements and data protection laws.

---

**Last Updated**: January 2024
**Version**: 1.0.0
